{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4cf9e09",
   "metadata": {},
   "source": [
    "### RAG pipeline - Data Ingestion to Vector DB Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0ddf479d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_community.document_loaders import PyPDFLoader, PyMuPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cf1bacfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Found 3 PDF files in the directory '../data/files':\n",
      "- business model canvas v1.pdf\n",
      "  Loaded 3 pages from business model canvas v1.pdf\n",
      "- Projeto de intervenção.pdf\n",
      "  Loaded 18 pages from Projeto de intervenção.pdf\n",
      "- Ricardo Miguel.pdf\n",
      "  Loaded 1 pages from Ricardo Miguel.pdf\n",
      "\n",
      "Total documents loaded: 22\n"
     ]
    }
   ],
   "source": [
    "### Read all pdf inside the directory\n",
    "def process_all_pdfs_in_directory(directory_path):\n",
    "    all_documents = []\n",
    "    pdf_dir = Path(directory_path)\n",
    "\n",
    "    # Find all PDF files in the directory\n",
    "    pdf_files = list(pdf_dir.glob(\"**/*.pdf\"))\n",
    "\n",
    "    print (f\"\\nFound {len(pdf_files)} PDF files in the directory '{directory_path}':\")\n",
    "\n",
    "    for pdf_file in pdf_files:\n",
    "        print(f\"- {pdf_file.name}\")\n",
    "        try:\n",
    "            loader = PyPDFLoader(str(pdf_file))\n",
    "            documents = loader.load()\n",
    "\n",
    "            # Add source information to metadata\n",
    "            for doc in documents:\n",
    "                doc.metadata[\"source\"] = pdf_file.name\n",
    "                doc.metadata['file_type'] = 'pdf'\n",
    "            all_documents.extend(documents)\n",
    "            print(f\"  Loaded {len(documents)} pages from {pdf_file.name}\")\n",
    "   \n",
    "        except Exception as e:\n",
    "            print(f\" Error: {e}\")\n",
    "    print(f\"\\nTotal documents loaded: {len(all_documents)}\")\n",
    "    return all_documents\n",
    "\n",
    "all_docs = process_all_pdfs_in_directory(\"../data/files\")  # Update with your directory path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b3001abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Text splitting get into chunks\n",
    "def split_documents(documents, chunk_size=1000, chunk_overlap=200):\n",
    "    \"\"\"Split documents into smaller chunks.\"\"\"\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=chunk_size,\n",
    "        chunk_overlap=chunk_overlap,\n",
    "        length_function=len,\n",
    "        separators=[\"\\n\\n\", \"\\n\", \" \", \"\"],\n",
    "    )\n",
    "    split_docs = text_splitter.split_documents(documents)\n",
    "    print(f\"\\nTotal documents after splitting: {len(split_docs)}\")\n",
    "\n",
    "    if split_docs:\n",
    "        print(f\"\\nExample chunk:\")\n",
    "        print(f\"Content: {split_docs[0].page_content[:200]}...\")\n",
    "        print(f\"Metadata: {split_docs[0].metadata}\")\n",
    "    return split_docs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b932c03b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total documents after splitting: 40\n",
      "\n",
      "Example chunk:\n",
      "Content: B u sin ess M od el\n",
      "C an vas 1.0...\n",
      "Metadata: {'producer': 'Canva', 'creator': 'Canva', 'creationdate': '2025-09-22T01:32:10+00:00', 'title': 'Helix Fusion Bistro', 'moddate': '2025-09-22T01:32:09+00:00', 'keywords': 'DAGzd4j7FzY,BACibNMnYqs,0', 'author': 'Ricardo Barros', 'source': 'business model canvas v1.pdf', 'total_pages': 3, 'page': 0, 'page_label': '1', 'file_type': 'pdf'}\n"
     ]
    }
   ],
   "source": [
    "chunks = split_documents(all_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f468d03",
   "metadata": {},
   "source": [
    "### Embedding and vectorStoreDB "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "33a18c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import chromadb\n",
    "from chromadb.config import Settings\n",
    "import uuid\n",
    "from typing import List, Dict, Any, Tuple\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "35c9b070",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded embedding model: all-MiniLM-L6-v2\n",
      "Model loaded sucessfully. Embedding dimension 384.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.EmbeddingManager at 0x148ea01a0>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class EmbeddingManager:\n",
    "    def __init__(self, model_name: str = \"all-MiniLM-L6-v2\"):\n",
    "        self.mode_name = model_name\n",
    "        self.model = None\n",
    "        self._load_model()\n",
    "    def _load_model(self):\n",
    "        \"\"\"Load the embedding model.\"\"\"\n",
    "        try:\n",
    "            self.model = SentenceTransformer(self.mode_name)\n",
    "            print(f\"Loaded embedding model: {self.mode_name}\")\n",
    "            print(f\"Model loaded sucessfully. Embedding dimension {self.model.get_sentence_embedding_dimension()}.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading model {self.mode_name}: {e}\")\n",
    "            raise\n",
    "\n",
    "    def generate_embeddings(self, texts: List[str]) -> np.ndarray:\n",
    "        \"\"\"Generate embeddings for a list of texts.\"\"\"\n",
    "        if not self.model:\n",
    "            raise ValueError(\"Model not loaded.\")\n",
    "        embeddings = self.model.encode(texts, convert_to_numpy=True)\n",
    "        return embeddings\n",
    "\n",
    "embedding_manager = EmbeddingManager()\n",
    "embedding_manager"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3a79947",
   "metadata": {},
   "source": [
    "### Vector Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da609e03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChromaDB initialized with collection: pdf_documents\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.VectorStore at 0x1696dabd0>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class VectorStore:\n",
    "    def __init__(self, collection_name: str = \"pdf_documents\", persist_directory: str = \"../data/vector_store\"):\n",
    "        self.collection_name = collection_name\n",
    "        self.persist_directory = persist_directory\n",
    "        self.client = None\n",
    "        self.collection = None\n",
    "        self._initialize_store()\n",
    "\n",
    "    def _initialize_store(self):\n",
    "        \"\"\"Initialize ChromaDB client and collection.\"\"\"\n",
    "        try:\n",
    "            os.makedirs(self.persist_directory, exist_ok=True)\n",
    "            self.client = chromadb.PersistentClient(path=self.persist_directory)\n",
    "            self.collection = self.client.get_or_create_collection(name=self.collection_name, metadata={\"description\": \"PDF Documents Collection\"})\n",
    "            print(f\"ChromaDB initialized with collection: {self.collection_name}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error initializing ChromaDB: {e}\")\n",
    "            raise\n",
    "\n",
    "    def add_documents(self, documents: List[Any], embeddings: np.ndarray):\n",
    "        \n",
    "        if len(documents) != len(embeddings):\n",
    "            raise ValueError(\"The number of documents and embeddings must match.\")\n",
    "        \"\"\"Add documents and their embeddings to the collection.\"\"\"\n",
    "        print(f\"Adding {len(documents)} documents to the collection '{self.collection_name}'...\")\n",
    "        ids = []\n",
    "        metadatas = []\n",
    "        documents_texts = []\n",
    "        embeddings_list = [] \n",
    "\n",
    "        for i, (doc,embedding) in enumerate(zip(documents, embeddings)):\n",
    "            # Generate a unique ID for each document\n",
    "            doc_id = f\"doc_{uuid.uuid4().hex[:8]}_{i}\"\n",
    "            ids.append(doc_id)\n",
    "            \n",
    "            # Prepare metadata\n",
    "            metadata = dict(doc.metadata)\n",
    "            metadata['doc_index'] = i\n",
    "            metadata['content_length'] = len(doc.page_content)\n",
    "            metadatas.append(metadata)\n",
    "\n",
    "            # Document content\n",
    "            documents_texts.append(doc.page_content)\n",
    "\n",
    "            # Embedding\n",
    "            embeddings_list.append(embedding.tolist())\n",
    "\n",
    "        # Add to collection\n",
    "        try: \n",
    "            self.collection.add(\n",
    "                ids=ids,\n",
    "                metadatas=metadatas,\n",
    "                documents=documents_texts,\n",
    "                embeddings=embeddings_list\n",
    "            )\n",
    "            print(f\"Successfully added {len(documents)} documents to the collection.\")\n",
    "            print(f\"Collection now has {self.collection.count()} documents.\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error initializing ChromaDB: {e}\")\n",
    "            raise\n",
    "    \n",
    "vector_store=VectorStore()\n",
    "vector_store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ccd44ffd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding 40 documents to the collection 'pdf_documents'...\n",
      "Successfully added 40 documents to the collection.\n",
      "Collection now has 166 documents.\n"
     ]
    }
   ],
   "source": [
    "## convert the text to embeddings\n",
    "texts = [doc.page_content for doc in chunks]\n",
    "\n",
    "## generate embeddings\n",
    "embeddings = embedding_manager.generate_embeddings(texts)\n",
    "\n",
    "## store in vector db\n",
    "vector_store.add_documents(chunks, embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd7d83a2",
   "metadata": {},
   "source": [
    "### Retriever Pipeline From VectorStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fbd0517d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RAGRetriever:\n",
    "    def __init__(self, vector_store: VectorStore, embedding_manager: EmbeddingManager):\n",
    "        \"\"\"\n",
    "        Initialize the retriever with a vector store and embedding manager.\n",
    "        \n",
    "        Args:\n",
    "            vector_store (VectorStore): The vector store instance.\n",
    "            embedding_manager (EmbeddingManager): The embedding manager instance.\n",
    "        \"\"\"\n",
    "        self.vector_store = vector_store\n",
    "        self.embedding_manager = embedding_manager\n",
    "\n",
    "    def retrieve(self, query: str, top_k: int = 5, score_threshold: float = 0.0) -> List[Dict[str, Any]]:\n",
    "        \"\"\"\n",
    "        Retrieve relevant documents for a given query.\n",
    "\n",
    "        Args:\n",
    "            query (str): The input query string.\n",
    "            top_k (int): The number of top documents to retrieve.\n",
    "            score_threshold (float): Minimum similarity score to consider a document relevant.\n",
    "\n",
    "        Returns:\n",
    "            List[Dict[str, Any]]: A list of retrieved documents with metadata and scores.\n",
    "        \n",
    "        \"\"\"\n",
    "        print(f\"Retrieving documents for query: '{query}'\")\n",
    "        print(f\"Top K: {top_k}, Score Threshold: {score_threshold}\")\n",
    "\n",
    "        # Generate query embedding\n",
    "        query_embedding = self.embedding_manager.generate_embeddings([query])[0]\n",
    "\n",
    "        # search in the vector store\n",
    "        try: \n",
    "            results = self.vector_store.collection.query(\n",
    "                query_embeddings=[query_embedding.tolist()],\n",
    "                n_results=top_k,\n",
    "            )\n",
    "            retrieved_docs = []\n",
    "\n",
    "            if results['documents'] and results['documents'][0]:\n",
    "                documents=results['documents'][0]\n",
    "                metadatas=results['metadatas'][0]\n",
    "                distances=results['distances'][0]\n",
    "                ids=results['ids'][0]\n",
    "                for i, (doc_id, document, metadata, distance) in enumerate(zip(ids, documents, metadatas, distances)):\n",
    "                    # convert distance to similarity score (ChormaDB uses cosine distance)\n",
    "                    similarity_score = 1 - distance\n",
    "                    if similarity_score >= score_threshold: \n",
    "                        retrieved_docs.append({\n",
    "                            'id': doc_id,\n",
    "                            'content': document,\n",
    "                            'metadata': metadata,\n",
    "                            'distance': distance,\n",
    "                            'rank': i + 1\n",
    "                        })\n",
    "                print(f\"Retrieved {len(retrieved_docs)} documents (after filtering)\")\n",
    "            else:\n",
    "                print(\"No documents found\")\n",
    "            return retrieved_docs\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error during retrieval: {e}\")\n",
    "            return []\n",
    "\n",
    "rag_retriever = RAGRetriever(vector_store, embedding_manager)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "344c2b97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving documents for query: 'Manutenção de computadores'\n",
      "Top K: 5, Score Threshold: 0.0\n",
      "Retrieved 5 documents (after filtering)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'id': 'doc_31845d84_0',\n",
       "  'content': 'Projeto  de  intervenção  \\n \\nManutenção  e  Reparação  de  Computadores  \\n   \\n                       \\n1',\n",
       "  'metadata': {'doc_index': 0,\n",
       "   'creationdate': '',\n",
       "   'page_label': '1',\n",
       "   'title': 'Projeto de intervenção',\n",
       "   'total_pages': 18,\n",
       "   'content_length': 103,\n",
       "   'page': 0,\n",
       "   'producer': 'Skia/PDF m140 Google Docs Renderer',\n",
       "   'file_type': 'pdf',\n",
       "   'source': 'Projeto de intervenção.pdf',\n",
       "   'creator': 'PyPDF'},\n",
       "  'distance': 0.4315428137779236,\n",
       "  'rank': 1},\n",
       " {'id': 'doc_5992a92d_4',\n",
       "  'content': 'Projeto  de  intervenção  \\n \\nManutenção  e  Reparação  de  Computadores  \\n   \\n                       \\n1',\n",
       "  'metadata': {'producer': 'Skia/PDF m140 Google Docs Renderer',\n",
       "   'page_label': '1',\n",
       "   'creationdate': '',\n",
       "   'content_length': 103,\n",
       "   'source': 'Projeto de intervenção.pdf',\n",
       "   'page': 0,\n",
       "   'title': 'Projeto de intervenção',\n",
       "   'creator': 'PyPDF',\n",
       "   'total_pages': 18,\n",
       "   'file_type': 'pdf',\n",
       "   'doc_index': 4},\n",
       "  'distance': 0.4315428137779236,\n",
       "  'rank': 2},\n",
       " {'id': 'doc_42525845_4',\n",
       "  'content': 'Projeto  de  intervenção  \\n \\nManutenção  e  Reparação  de  Computadores  \\n   \\n                       \\n1',\n",
       "  'metadata': {'total_pages': 18,\n",
       "   'content_length': 103,\n",
       "   'file_type': 'pdf',\n",
       "   'doc_index': 4,\n",
       "   'creationdate': '',\n",
       "   'page': 0,\n",
       "   'page_label': '1',\n",
       "   'creator': 'PyPDF',\n",
       "   'producer': 'Skia/PDF m140 Google Docs Renderer',\n",
       "   'title': 'Projeto de intervenção',\n",
       "   'source': 'Projeto de intervenção.pdf'},\n",
       "  'distance': 0.4315428137779236,\n",
       "  'rank': 3},\n",
       " {'id': 'doc_5efdfa23_4',\n",
       "  'content': 'Projeto  de  intervenção  \\n \\nManutenção  e  Reparação  de  Computadores  \\n   \\n                       \\n1',\n",
       "  'metadata': {'producer': 'Skia/PDF m140 Google Docs Renderer',\n",
       "   'title': 'Projeto de intervenção',\n",
       "   'content_length': 103,\n",
       "   'creationdate': '',\n",
       "   'creator': 'PyPDF',\n",
       "   'file_type': 'pdf',\n",
       "   'doc_index': 4,\n",
       "   'total_pages': 18,\n",
       "   'page': 0,\n",
       "   'source': 'Projeto de intervenção.pdf',\n",
       "   'page_label': '1'},\n",
       "  'distance': 0.4315428137779236,\n",
       "  'rank': 4},\n",
       " {'id': 'doc_8e9d681f_10',\n",
       "  'content': 'Formador :  Eng.  Ricardo  Barros  \\n \\nDesignação  da  formação  \\nManutenção  e  reparação  de  computadores  \\nEnquadramento  do  tema  \\nA  crescente  digitalização  da  sociedade  e  a  presença  constante  da  tecnologia  na  vida  pessoal  e  \\nprofissional\\n \\ntornam\\n \\nessencial\\n \\no\\n \\ndesenvolvimento\\n \\nde\\n \\ncompetências\\n \\ntécnicas\\n \\nna\\n \\nárea\\n \\nda\\n \\ninformática.\\n \\nEntre\\n \\nessas\\n \\ncompetências,\\n \\ndestaca-se\\n \\no\\n \\ndomínio\\n \\ndos\\n \\nconhecimentos\\n \\nbásicos\\n \\nde\\n \\nhardware\\n \\ne\\n \\na\\n \\ncapacidade\\n \\nde\\n \\nmanutenção\\n \\ne\\n \\nreparação\\n \\nde\\n \\ncomputadores.\\n \\nA  formação  em  manutenção  e  reparação  de  computadores  permite  aos  formandos  \\ncompreenderem,\\n \\nde\\n \\nforma\\n \\nprática,\\n \\no\\n \\nfuncionamento\\n \\ninterno\\n \\nde\\n \\num\\n \\nsistema\\n \\ninformático,\\n \\npromovendo\\n \\na\\n \\nautonomia\\n \\ntecnológica\\n \\ne\\n \\na\\n \\ncapacidade\\n \\nde\\n \\ndiagnóstico\\n \\ne\\n \\nresolução\\n \\nde\\n \\nproblemas.\\n \\nEstas\\n \\ncompetências\\n \\nsão\\n \\nparticularmente\\n \\nrelevantes\\n \\nnum\\n \\ncontexto\\n \\nde\\n \\nrequalificação\\n \\nprofissional,\\n \\nempregabilidade\\n \\njovem',\n",
       "  'metadata': {'page_label': '3',\n",
       "   'file_type': 'pdf',\n",
       "   'creationdate': '',\n",
       "   'total_pages': 18,\n",
       "   'content_length': 998,\n",
       "   'page': 2,\n",
       "   'source': 'Projeto de intervenção.pdf',\n",
       "   'creator': 'PyPDF',\n",
       "   'title': 'Projeto de intervenção',\n",
       "   'doc_index': 10,\n",
       "   'producer': 'Skia/PDF m140 Google Docs Renderer'},\n",
       "  'distance': 0.6785562038421631,\n",
       "  'rank': 5}]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_retriever.retrieve(\"Manutenção de computadores\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fec6bec",
   "metadata": {},
   "source": [
    "### Integration vectordb context pipeline with llm output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd7bd19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "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\n"
     ]
    }
   ],
   "source": [
    "### Simple RAG with Groq LLM\n",
    "\n",
    "from langchain_groq import ChatGroq\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "## init the grop llm\n",
    "groq_api_key = os.getenv(\"GROQ_API_KEY\")\n",
    "llm = ChatGroq(groq_api_key=groq_api_key, model_name=\"llama-3.1-8b-instant\", temperature=0.1, max_tokens=1024)\n",
    "print(os.getenv(\"GROQ_API_KEY\"))\n",
    "\n",
    "## simple rag function: retrieve context + generate response\n",
    "def rag_simple(query, retriever, llm, top_k=5):\n",
    "    ## retriver context\n",
    "    results = retriever.retrieve(query,top_k=top_k)\n",
    "    context = \"\\n\\n\".join([doc['content'] for doc in results]) if results else \"\"\n",
    "    if not context:\n",
    "        return \"No relevant content\"\n",
    "    \n",
    "    ## generate answer using groq\n",
    "    prompt=f\"\"\"Use the following context to answer the question concisely.\n",
    "        Context:\n",
    "        {context}\n",
    "\n",
    "        Question: {query}\n",
    "\n",
    "        Answer: \"\"\"\n",
    "\n",
    "    response = llm.invoke([prompt.format(context=context, query=query)])\n",
    "    return response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "443d44a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving documents for query: 'Quem é Ricardo Barros quais sao a experiencias'\n",
      "Top K: 5, Score Threshold: 0.0\n",
      "Retrieved 5 documents (after filtering)\n",
      "Não há informações disponíveis sobre as experiências de Ricardo Barros no contexto fornecido. No entanto, posso sugerir que ele é um engenheiro com experiência em formação e desenvolvimento de habilidades, pois está listado como formador em um índice que inclui temas como motivação, gestão de tempo e aprendizagem.\n"
     ]
    }
   ],
   "source": [
    "answer = rag_simple(\"Quem é Ricardo Barros quais sao a experiencias\", rag_retriever, llm)\n",
    "print(answer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
